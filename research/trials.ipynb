{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "print(\"Ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/sharveshsakthivel/Documents/Projects/Medical-Chatbot/research'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/sharveshsakthivel/Documents/Projects/Medical-Chatbot'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Data From the PDF File\n",
    "def load_pdf_file(data):\n",
    "    loader= DirectoryLoader(data,\n",
    "                            glob=\"*.pdf\",\n",
    "                            loader_cls=PyPDFLoader)\n",
    "\n",
    "    documents=loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data=load_pdf_file(data='/Users/sharveshsakthivel/Documents/Projects/Medical-Chatbot/Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the Data into Text Chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks=text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Text Chunks 5860\n"
     ]
    }
   ],
   "source": [
    "text_chunks=text_split(extracted_data)\n",
    "print(\"Length of Text Chunks\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the Embeddings from Hugging Face\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.1\n",
      "0.29.1\n"
     ]
    }
   ],
   "source": [
    "import sentence_transformers\n",
    "import huggingface_hub\n",
    "\n",
    "print(sentence_transformers.__version__)\n",
    "print(huggingface_hub.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY=os.environ.get(\"PINECONE_API_KEY\")\n",
    "GEMINIAI_API_KEY=os.environ.get(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while installing plugin inference: property 'inference' of 'PineconeGRPC' object has no setter\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/pinecone_plugin_interface/actions/installation.py\", line 13, in install_plugins\n",
      "    setattr(target, plugin.namespace, impl(target.config, plugin_client_builder))\n",
      "AttributeError: property 'inference' of 'PineconeGRPC' object has no setter\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"name\": \"llmapp\",\n",
       "    \"metric\": \"cosine\",\n",
       "    \"host\": \"llmapp-offawuh.svc.aped-4627-b74a.pinecone.io\",\n",
       "    \"spec\": {\n",
       "        \"serverless\": {\n",
       "            \"cloud\": \"aws\",\n",
       "            \"region\": \"us-east-1\"\n",
       "        }\n",
       "    },\n",
       "    \"status\": {\n",
       "        \"ready\": true,\n",
       "        \"state\": \"Ready\"\n",
       "    },\n",
       "    \"vector_type\": \"dense\",\n",
       "    \"dimension\": 384,\n",
       "    \"deletion_protection\": \"disabled\",\n",
       "    \"tags\": null\n",
       "}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "import os\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"llmapp\"\n",
    "\n",
    "pc.delete_index(\"llmapp\")\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=384, \n",
    "    metric=\"cosine\", \n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\", \n",
    "        region=\"us-east-1\"\n",
    "    ) \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "400 API key not valid. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\n, locale: \"en-US\"\nmessage: \"API key not valid. Please pass a valid API key.\"\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[122], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[39m=\u001b[39m genai\u001b[39m.\u001b[39mGenerativeModel(\u001b[39m\"\u001b[39m\u001b[39mgemini-2.0-flash\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m response \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate_content(\u001b[39m\"\u001b[39;49m\u001b[39mExplain how AI works\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(response\u001b[39m.\u001b[39mtext)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/google/generativeai/generative_models.py:331\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[39mreturn\u001b[39;00m generation_types\u001b[39m.\u001b[39mGenerateContentResponse\u001b[39m.\u001b[39mfrom_iterator(iterator)\n\u001b[1;32m    330\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m         response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49mgenerate_content(\n\u001b[1;32m    332\u001b[0m             request,\n\u001b[1;32m    333\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mrequest_options,\n\u001b[1;32m    334\u001b[0m         )\n\u001b[1;32m    335\u001b[0m         \u001b[39mreturn\u001b[39;00m generation_types\u001b[39m.\u001b[39mGenerateContentResponse\u001b[39m.\u001b[39mfrom_response(response)\n\u001b[1;32m    336\u001b[0m \u001b[39mexcept\u001b[39;00m google\u001b[39m.\u001b[39mapi_core\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mInvalidArgument \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:835\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    834\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 835\u001b[0m response \u001b[39m=\u001b[39m rpc(\n\u001b[1;32m    836\u001b[0m     request,\n\u001b[1;32m    837\u001b[0m     retry\u001b[39m=\u001b[39;49mretry,\n\u001b[1;32m    838\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    839\u001b[0m     metadata\u001b[39m=\u001b[39;49mmetadata,\n\u001b[1;32m    840\u001b[0m )\n\u001b[1;32m    842\u001b[0m \u001b[39m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    843\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compression \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mcompression\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped_func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[39m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initial, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maximum, multiplier\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[39mreturn\u001b[39;00m retry_target(\n\u001b[1;32m    294\u001b[0m     target,\n\u001b[1;32m    295\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predicate,\n\u001b[1;32m    296\u001b[0m     sleep_generator,\n\u001b[1;32m    297\u001b[0m     timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_timeout,\n\u001b[1;32m    298\u001b[0m     on_error\u001b[39m=\u001b[39;49mon_error,\n\u001b[1;32m    299\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[39m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[39m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     _retry_error_helper(\n\u001b[1;32m    154\u001b[0m         exc,\n\u001b[1;32m    155\u001b[0m         deadline,\n\u001b[1;32m    156\u001b[0m         sleep,\n\u001b[1;32m    157\u001b[0m         error_list,\n\u001b[1;32m    158\u001b[0m         predicate,\n\u001b[1;32m    159\u001b[0m         on_error,\n\u001b[1;32m    160\u001b[0m         exception_factory,\n\u001b[1;32m    161\u001b[0m         timeout,\n\u001b[1;32m    162\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[39m.\u001b[39msleep(sleep)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[39m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[39m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[39mraise\u001b[39;00m final_exc \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[39mif\u001b[39;00m on_error_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39mfor\u001b[39;00m sleep \u001b[39min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[39m=\u001b[39m target()\n\u001b[1;32m    145\u001b[0m         \u001b[39mif\u001b[39;00m inspect\u001b[39m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/google/api_core/timeout.py:130\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         remaining_timeout \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout\n\u001b[1;32m    128\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m remaining_timeout\n\u001b[0;32m--> 130\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[39mreturn\u001b[39;00m callable_(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[39mexcept\u001b[39;00m grpc\u001b[39m.\u001b[39mRpcError \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mfrom_grpc_error(exc) \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mexc\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgument\u001b[0m: 400 API key not valid. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\n, locale: \"en-US\"\nmessage: \"API key not valid. Please pass a valid API key.\"\n]"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "\n",
    "response = model.generate_content(\"Explain how AI works\")\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "os.environ[\"GEMINIAI_API_KEY\"] = \"GEMINI_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while installing plugin inference: property 'inference' of 'Pinecone' object has no setter\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/pinecone_plugin_interface/actions/installation.py\", line 13, in install_plugins\n",
      "    setattr(target, plugin.namespace, impl(target.config, plugin_client_builder))\n",
      "AttributeError: property 'inference' of 'Pinecone' object has no setter\n"
     ]
    }
   ],
   "source": [
    "# Embed each chunk and upsert the embeddings into your Pinecone index.\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while installing plugin inference: property 'inference' of 'Pinecone' object has no setter\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/pinecone_plugin_interface/actions/installation.py\", line 13, in install_plugins\n",
      "    setattr(target, plugin.namespace, impl(target.config, plugin_client_builder))\n",
      "AttributeError: property 'inference' of 'Pinecone' object has no setter\n"
     ]
    }
   ],
   "source": [
    "# Load Existing index \n",
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "# Embed each chunk and upsert the embeddings into your Pinecone index.\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x1473a1c90>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(\"What is Acne?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='d0cea3aa-3e70-4699-a948-9df028a98eaa', metadata={'creationdate': '2004-12-18T17:00:02-05:00', 'creator': 'PyPDF', 'moddate': '2004-12-18T16:15:31-06:00', 'page': 39.0, 'page_label': '40', 'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'source': '/Users/sharveshsakthivel/Documents/Projects/Medical-Chatbot/Data/Medical_book.pdf', 'total_pages': 637.0}, page_content='GALE ENCYCLOPEDIA OF MEDICINE 226\\nAcne\\nGEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 26'),\n",
       " Document(id='36146ad7-0873-4c5c-a34a-5f7c20c8ae44', metadata={'creationdate': '2004-12-18T17:00:02-05:00', 'creator': 'PyPDF', 'moddate': '2004-12-18T16:15:31-06:00', 'page': 38.0, 'page_label': '39', 'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'source': '/Users/sharveshsakthivel/Documents/Projects/Medical-Chatbot/Data/Medical_book.pdf', 'total_pages': 637.0}, page_content='GALE ENCYCLOPEDIA OF MEDICINE 2 25\\nAcne\\nAcne vulgaris affecting a woman’s face. Acne is the general\\nname given to a skin disorder in which the sebaceous\\nglands become inflamed.(Photograph by Biophoto Associ-\\nates, Photo Researchers, Inc. Reproduced by permission.)\\nGEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 25'),\n",
       " Document(id='29f49b80-a553-4655-be59-97c3d40bb6e5', metadata={'creationdate': '2004-12-18T17:00:02-05:00', 'creator': 'PyPDF', 'moddate': '2004-12-18T16:15:31-06:00', 'page': 37.0, 'page_label': '38', 'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'source': '/Users/sharveshsakthivel/Documents/Projects/Medical-Chatbot/Data/Medical_book.pdf', 'total_pages': 637.0}, page_content='Acidosis see Respiratory acidosis; Renal\\ntubular acidosis; Metabolic acidosis\\nAcne\\nDefinition\\nAcne is a common skin disease characterized by\\npimples on the face, chest, and back. It occurs when the\\npores of the skin become clogged with oil, dead skin\\ncells, and bacteria.\\nDescription\\nAcne vulgaris, the medical term for common acne, is\\nthe most common skin disease. It affects nearly 17 million\\npeople in the United States. While acne can arise at any')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "llm = OpenAI(temperature=0.4, max_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[39m=\u001b[39m rag_chain\u001b[39m.\u001b[39;49minvoke({\u001b[39m\"\u001b[39;49m\u001b[39minput\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mwhat is Acromegaly and gigantism?\u001b[39;49m\u001b[39m\"\u001b[39;49m})\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(response[\u001b[39m\"\u001b[39m\u001b[39manswer\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/langchain_core/runnables/base.py:5360\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5354\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39minvoke\u001b[39m(\n\u001b[1;32m   5355\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   5356\u001b[0m     \u001b[39minput\u001b[39m: Input,\n\u001b[1;32m   5357\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   5358\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   5359\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Output:\n\u001b[0;32m-> 5360\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbound\u001b[39m.\u001b[39;49minvoke(\n\u001b[1;32m   5361\u001b[0m         \u001b[39minput\u001b[39;49m,\n\u001b[1;32m   5362\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_merge_configs(config),\n\u001b[1;32m   5363\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m{\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs},\n\u001b[1;32m   5364\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/langchain_core/runnables/base.py:3024\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39mrun(step\u001b[39m.\u001b[39minvoke, \u001b[39minput\u001b[39m, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   3023\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 3024\u001b[0m             \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39mrun(step\u001b[39m.\u001b[39minvoke, \u001b[39minput\u001b[39m, config)\n\u001b[1;32m   3025\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[1;32m   3026\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/langchain_core/runnables/passthrough.py:494\u001b[0m, in \u001b[0;36mRunnableAssign.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39minvoke\u001b[39m(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    490\u001b[0m     \u001b[39minput\u001b[39m: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, Any],\n\u001b[1;32m    491\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    492\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    493\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, Any]:\n\u001b[0;32m--> 494\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_with_config(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_invoke, \u001b[39minput\u001b[39;49m, config, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/langchain_core/runnables/base.py:1922\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1918\u001b[0m     context \u001b[39m=\u001b[39m copy_context()\n\u001b[1;32m   1919\u001b[0m     context\u001b[39m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m   1920\u001b[0m     output \u001b[39m=\u001b[39m cast(\n\u001b[1;32m   1921\u001b[0m         Output,\n\u001b[0;32m-> 1922\u001b[0m         context\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m   1923\u001b[0m             call_func_with_variable_args,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1924\u001b[0m             func,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1925\u001b[0m             \u001b[39minput\u001b[39;49m,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1926\u001b[0m             config,\n\u001b[1;32m   1927\u001b[0m             run_manager,\n\u001b[1;32m   1928\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1929\u001b[0m         ),\n\u001b[1;32m   1930\u001b[0m     )\n\u001b[1;32m   1931\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1932\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/langchain_core/runnables/config.py:396\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[39mif\u001b[39;00m run_manager \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    395\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m run_manager\n\u001b[0;32m--> 396\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/langchain_core/runnables/passthrough.py:481\u001b[0m, in \u001b[0;36mRunnableAssign._invoke\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mThe input to RunnablePassthrough.assign() must be a dict.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    477\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)  \u001b[39m# noqa: TRY004\u001b[39;00m\n\u001b[1;32m    479\u001b[0m \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m    480\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m,\n\u001b[0;32m--> 481\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmapper\u001b[39m.\u001b[39;49minvoke(\n\u001b[1;32m    482\u001b[0m         \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    483\u001b[0m         patch_config(config, callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child()),\n\u001b[1;32m    484\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    485\u001b[0m     ),\n\u001b[1;32m    486\u001b[0m }\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/langchain_core/runnables/base.py:3729\u001b[0m, in \u001b[0;36mRunnableParallel.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3724\u001b[0m     \u001b[39mwith\u001b[39;00m get_executor_for_config(config) \u001b[39mas\u001b[39;00m executor:\n\u001b[1;32m   3725\u001b[0m         futures \u001b[39m=\u001b[39m [\n\u001b[1;32m   3726\u001b[0m             executor\u001b[39m.\u001b[39msubmit(_invoke_step, step, \u001b[39minput\u001b[39m, config, key)\n\u001b[1;32m   3727\u001b[0m             \u001b[39mfor\u001b[39;00m key, step \u001b[39min\u001b[39;00m steps\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   3728\u001b[0m         ]\n\u001b[0;32m-> 3729\u001b[0m         output \u001b[39m=\u001b[39m {key: future\u001b[39m.\u001b[39;49mresult() \u001b[39mfor\u001b[39;49;00m key, future \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(steps, futures)}\n\u001b[1;32m   3730\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[1;32m   3731\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/langchain_core/runnables/base.py:3729\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3724\u001b[0m     \u001b[39mwith\u001b[39;00m get_executor_for_config(config) \u001b[39mas\u001b[39;00m executor:\n\u001b[1;32m   3725\u001b[0m         futures \u001b[39m=\u001b[39m [\n\u001b[1;32m   3726\u001b[0m             executor\u001b[39m.\u001b[39msubmit(_invoke_step, step, \u001b[39minput\u001b[39m, config, key)\n\u001b[1;32m   3727\u001b[0m             \u001b[39mfor\u001b[39;00m key, step \u001b[39min\u001b[39;00m steps\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   3728\u001b[0m         ]\n\u001b[0;32m-> 3729\u001b[0m         output \u001b[39m=\u001b[39m {key: future\u001b[39m.\u001b[39;49mresult() \u001b[39mfor\u001b[39;00m key, future \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(steps, futures)}\n\u001b[1;32m   3730\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[1;32m   3731\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/concurrent/futures/_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    455\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 456\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    457\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs)\n\u001b[1;32m     59\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfuture\u001b[39m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/langchain_core/runnables/base.py:3713\u001b[0m, in \u001b[0;36mRunnableParallel.invoke.<locals>._invoke_step\u001b[0;34m(step, input, config, key)\u001b[0m\n\u001b[1;32m   3711\u001b[0m context \u001b[39m=\u001b[39m copy_context()\n\u001b[1;32m   3712\u001b[0m context\u001b[39m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[0;32m-> 3713\u001b[0m \u001b[39mreturn\u001b[39;00m context\u001b[39m.\u001b[39mrun(\n\u001b[1;32m   3714\u001b[0m     step\u001b[39m.\u001b[39minvoke,\n\u001b[1;32m   3715\u001b[0m     \u001b[39minput\u001b[39m,\n\u001b[1;32m   3716\u001b[0m     child_config,\n\u001b[1;32m   3717\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/langchain_core/runnables/base.py:5360\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5354\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39minvoke\u001b[39m(\n\u001b[1;32m   5355\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   5356\u001b[0m     \u001b[39minput\u001b[39m: Input,\n\u001b[1;32m   5357\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   5358\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   5359\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Output:\n\u001b[0;32m-> 5360\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbound\u001b[39m.\u001b[39;49minvoke(\n\u001b[1;32m   5361\u001b[0m         \u001b[39minput\u001b[39;49m,\n\u001b[1;32m   5362\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_merge_configs(config),\n\u001b[1;32m   5363\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m{\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs},\n\u001b[1;32m   5364\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/langchain_core/runnables/base.py:3024\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39mrun(step\u001b[39m.\u001b[39minvoke, \u001b[39minput\u001b[39m, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   3023\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 3024\u001b[0m             \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39mrun(step\u001b[39m.\u001b[39minvoke, \u001b[39minput\u001b[39m, config)\n\u001b[1;32m   3025\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[1;32m   3026\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/langchain_core/language_models/llms.py:387\u001b[0m, in \u001b[0;36mBaseLLM.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39minvoke\u001b[39m(\n\u001b[1;32m    378\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    379\u001b[0m     \u001b[39minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    384\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    385\u001b[0m     config \u001b[39m=\u001b[39m ensure_config(config)\n\u001b[1;32m    386\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 387\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[1;32m    388\u001b[0m             [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_input(\u001b[39minput\u001b[39;49m)],\n\u001b[1;32m    389\u001b[0m             stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    390\u001b[0m             callbacks\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcallbacks\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    391\u001b[0m             tags\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mtags\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    392\u001b[0m             metadata\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmetadata\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    393\u001b[0m             run_name\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mrun_name\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    394\u001b[0m             run_id\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mrun_id\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    395\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    396\u001b[0m         )\n\u001b[1;32m    397\u001b[0m         \u001b[39m.\u001b[39mgenerations[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[1;32m    398\u001b[0m         \u001b[39m.\u001b[39mtext\n\u001b[1;32m    399\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/langchain_core/language_models/llms.py:760\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mgenerate_prompt\u001b[39m(\n\u001b[1;32m    753\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    754\u001b[0m     prompts: \u001b[39mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    758\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    759\u001b[0m     prompt_strings \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_string() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[0;32m--> 760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_strings, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/langchain_core/language_models/llms.py:963\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m get_llm_cache() \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m     run_managers \u001b[39m=\u001b[39m [\n\u001b[1;32m    950\u001b[0m         callback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[1;32m    951\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_serialized,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    961\u001b[0m         )\n\u001b[1;32m    962\u001b[0m     ]\n\u001b[0;32m--> 963\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_helper(\n\u001b[1;32m    964\u001b[0m         prompts, stop, run_managers, \u001b[39mbool\u001b[39;49m(new_arg_supported), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    965\u001b[0m     )\n\u001b[1;32m    966\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n\u001b[1;32m    967\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(missing_prompts) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/langchain_core/language_models/llms.py:784\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m_generate_helper\u001b[39m(\n\u001b[1;32m    775\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    776\u001b[0m     prompts: \u001b[39mlist\u001b[39m[\u001b[39mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    780\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    781\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    782\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    783\u001b[0m         output \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 784\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[1;32m    785\u001b[0m                 prompts,\n\u001b[1;32m    786\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    787\u001b[0m                 \u001b[39m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    788\u001b[0m                 run_manager\u001b[39m=\u001b[39;49mrun_managers[\u001b[39m0\u001b[39;49m] \u001b[39mif\u001b[39;49;00m run_managers \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    789\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    790\u001b[0m             )\n\u001b[1;32m    791\u001b[0m             \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    792\u001b[0m             \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(prompts, stop\u001b[39m=\u001b[39mstop)\n\u001b[1;32m    793\u001b[0m         )\n\u001b[1;32m    794\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    795\u001b[0m         \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/langchain_openai/llms/base.py:343\u001b[0m, in \u001b[0;36mBaseOpenAI._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m     choices\u001b[39m.\u001b[39mappend(\n\u001b[1;32m    328\u001b[0m         {\n\u001b[1;32m    329\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m: generation\u001b[39m.\u001b[39mtext,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    340\u001b[0m         }\n\u001b[1;32m    341\u001b[0m     )\n\u001b[1;32m    342\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 343\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(prompt\u001b[39m=\u001b[39;49m_prompts, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    344\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, \u001b[39mdict\u001b[39m):\n\u001b[1;32m    345\u001b[0m         \u001b[39m# V1 client returns the response in an PyDantic object instead of\u001b[39;00m\n\u001b[1;32m    346\u001b[0m         \u001b[39m# dict. For the transition period, we deep convert it to dict.\u001b[39;00m\n\u001b[1;32m    347\u001b[0m         response \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mmodel_dump()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/openai/_utils/_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m             msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing required argument: \u001b[39m\u001b[39m{\u001b[39;00mquote(missing[\u001b[39m0\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 279\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/openai/resources/completions.py:539\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, model, prompt, best_of, echo, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, seed, stop, stream, stream_options, suffix, temperature, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[39m@required_args\u001b[39m([\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m\"\u001b[39m], [\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    511\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcreate\u001b[39m(\n\u001b[1;32m    512\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    537\u001b[0m     timeout: \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m httpx\u001b[39m.\u001b[39mTimeout \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m|\u001b[39m NotGiven \u001b[39m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    538\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Completion \u001b[39m|\u001b[39m Stream[Completion]:\n\u001b[0;32m--> 539\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[1;32m    540\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m/completions\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    541\u001b[0m         body\u001b[39m=\u001b[39;49mmaybe_transform(\n\u001b[1;32m    542\u001b[0m             {\n\u001b[1;32m    543\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m: model,\n\u001b[1;32m    544\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mprompt\u001b[39;49m\u001b[39m\"\u001b[39;49m: prompt,\n\u001b[1;32m    545\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mbest_of\u001b[39;49m\u001b[39m\"\u001b[39;49m: best_of,\n\u001b[1;32m    546\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mecho\u001b[39;49m\u001b[39m\"\u001b[39;49m: echo,\n\u001b[1;32m    547\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfrequency_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: frequency_penalty,\n\u001b[1;32m    548\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogit_bias\u001b[39;49m\u001b[39m\"\u001b[39;49m: logit_bias,\n\u001b[1;32m    549\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogprobs\u001b[39;49m\u001b[39m\"\u001b[39;49m: logprobs,\n\u001b[1;32m    550\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmax_tokens\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_tokens,\n\u001b[1;32m    551\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mn\u001b[39;49m\u001b[39m\"\u001b[39;49m: n,\n\u001b[1;32m    552\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mpresence_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: presence_penalty,\n\u001b[1;32m    553\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mseed\u001b[39;49m\u001b[39m\"\u001b[39;49m: seed,\n\u001b[1;32m    554\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstop\u001b[39;49m\u001b[39m\"\u001b[39;49m: stop,\n\u001b[1;32m    555\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstream\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream,\n\u001b[1;32m    556\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstream_options\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream_options,\n\u001b[1;32m    557\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39msuffix\u001b[39;49m\u001b[39m\"\u001b[39;49m: suffix,\n\u001b[1;32m    558\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtemperature\u001b[39;49m\u001b[39m\"\u001b[39;49m: temperature,\n\u001b[1;32m    559\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_p\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_p,\n\u001b[1;32m    560\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m: user,\n\u001b[1;32m    561\u001b[0m             },\n\u001b[1;32m    562\u001b[0m             completion_create_params\u001b[39m.\u001b[39;49mCompletionCreateParams,\n\u001b[1;32m    563\u001b[0m         ),\n\u001b[1;32m    564\u001b[0m         options\u001b[39m=\u001b[39;49mmake_request_options(\n\u001b[1;32m    565\u001b[0m             extra_headers\u001b[39m=\u001b[39;49mextra_headers, extra_query\u001b[39m=\u001b[39;49mextra_query, extra_body\u001b[39m=\u001b[39;49mextra_body, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    566\u001b[0m         ),\n\u001b[1;32m    567\u001b[0m         cast_to\u001b[39m=\u001b[39;49mCompletion,\n\u001b[1;32m    568\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    569\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mStream[Completion],\n\u001b[1;32m    570\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/openai/_base_client.py:1290\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1276\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mpost\u001b[39m(\n\u001b[1;32m   1277\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1278\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1285\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1286\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m   1287\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(\n\u001b[1;32m   1288\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mto_httpx_files(files), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[1;32m   1289\u001b[0m     )\n\u001b[0;32m-> 1290\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(cast_to, opts, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/openai/_base_client.py:967\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m     retries_taken \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 967\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[1;32m    968\u001b[0m     cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[1;32m    969\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m    970\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    971\u001b[0m     stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m    972\u001b[0m     retries_taken\u001b[39m=\u001b[39;49mretries_taken,\n\u001b[1;32m    973\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/openai/_base_client.py:1056\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[39mif\u001b[39;00m remaining_retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_retry(err\u001b[39m.\u001b[39mresponse):\n\u001b[1;32m   1055\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mclose()\n\u001b[0;32m-> 1056\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retry_request(\n\u001b[1;32m   1057\u001b[0m         input_options,\n\u001b[1;32m   1058\u001b[0m         cast_to,\n\u001b[1;32m   1059\u001b[0m         retries_taken\u001b[39m=\u001b[39;49mretries_taken,\n\u001b[1;32m   1060\u001b[0m         response_headers\u001b[39m=\u001b[39;49merr\u001b[39m.\u001b[39;49mresponse\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m   1061\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m   1062\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m   1063\u001b[0m     )\n\u001b[1;32m   1065\u001b[0m \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1067\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/openai/_base_client.py:1105\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[39m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1102\u001b[0m \u001b[39m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1103\u001b[0m time\u001b[39m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1105\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[1;32m   1106\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m   1107\u001b[0m     cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[1;32m   1108\u001b[0m     retries_taken\u001b[39m=\u001b[39;49mretries_taken \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[1;32m   1109\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m   1110\u001b[0m     stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m   1111\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/openai/_base_client.py:1056\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[39mif\u001b[39;00m remaining_retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_retry(err\u001b[39m.\u001b[39mresponse):\n\u001b[1;32m   1055\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mclose()\n\u001b[0;32m-> 1056\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retry_request(\n\u001b[1;32m   1057\u001b[0m         input_options,\n\u001b[1;32m   1058\u001b[0m         cast_to,\n\u001b[1;32m   1059\u001b[0m         retries_taken\u001b[39m=\u001b[39;49mretries_taken,\n\u001b[1;32m   1060\u001b[0m         response_headers\u001b[39m=\u001b[39;49merr\u001b[39m.\u001b[39;49mresponse\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m   1061\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m   1062\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m   1063\u001b[0m     )\n\u001b[1;32m   1065\u001b[0m \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1067\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/openai/_base_client.py:1105\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[39m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1102\u001b[0m \u001b[39m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1103\u001b[0m time\u001b[39m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1105\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[1;32m   1106\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m   1107\u001b[0m     cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[1;32m   1108\u001b[0m     retries_taken\u001b[39m=\u001b[39;49mretries_taken \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[1;32m   1109\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m   1110\u001b[0m     stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m   1111\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/openai/_base_client.py:1071\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1068\u001b[0m         err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mread()\n\u001b[1;32m   1070\u001b[0m     log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mRe-raising status error\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1071\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_status_error_from_response(err\u001b[39m.\u001b[39mresponse) \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_response(\n\u001b[1;32m   1074\u001b[0m     cast_to\u001b[39m=\u001b[39mcast_to,\n\u001b[1;32m   1075\u001b[0m     options\u001b[39m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1079\u001b[0m     retries_taken\u001b[39m=\u001b[39mretries_taken,\n\u001b[1;32m   1080\u001b[0m )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"what is Acromegaly and gigantism?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[39m=\u001b[39m rag_chain\u001b[39m.\u001b[39;49minvoke({\u001b[39m\"\u001b[39;49m\u001b[39minput\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mWhat is stats?\u001b[39;49m\u001b[39m\"\u001b[39;49m})\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(response[\u001b[39m\"\u001b[39m\u001b[39manswer\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/langchain_core/runnables/base.py:5360\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5354\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39minvoke\u001b[39m(\n\u001b[1;32m   5355\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   5356\u001b[0m     \u001b[39minput\u001b[39m: Input,\n\u001b[1;32m   5357\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   5358\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   5359\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Output:\n\u001b[0;32m-> 5360\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbound\u001b[39m.\u001b[39;49minvoke(\n\u001b[1;32m   5361\u001b[0m         \u001b[39minput\u001b[39;49m,\n\u001b[1;32m   5362\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_merge_configs(config),\n\u001b[1;32m   5363\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m{\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs},\n\u001b[1;32m   5364\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/langchain_core/runnables/base.py:3024\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39mrun(step\u001b[39m.\u001b[39minvoke, \u001b[39minput\u001b[39m, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   3023\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 3024\u001b[0m             \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39mrun(step\u001b[39m.\u001b[39minvoke, \u001b[39minput\u001b[39m, config)\n\u001b[1;32m   3025\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[1;32m   3026\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/langchain_core/runnables/passthrough.py:494\u001b[0m, in \u001b[0;36mRunnableAssign.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39minvoke\u001b[39m(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    490\u001b[0m     \u001b[39minput\u001b[39m: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, Any],\n\u001b[1;32m    491\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    492\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    493\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, Any]:\n\u001b[0;32m--> 494\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_with_config(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_invoke, \u001b[39minput\u001b[39;49m, config, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/langchain_core/runnables/base.py:1922\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1918\u001b[0m     context \u001b[39m=\u001b[39m copy_context()\n\u001b[1;32m   1919\u001b[0m     context\u001b[39m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m   1920\u001b[0m     output \u001b[39m=\u001b[39m cast(\n\u001b[1;32m   1921\u001b[0m         Output,\n\u001b[0;32m-> 1922\u001b[0m         context\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m   1923\u001b[0m             call_func_with_variable_args,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1924\u001b[0m             func,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1925\u001b[0m             \u001b[39minput\u001b[39;49m,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1926\u001b[0m             config,\n\u001b[1;32m   1927\u001b[0m             run_manager,\n\u001b[1;32m   1928\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1929\u001b[0m         ),\n\u001b[1;32m   1930\u001b[0m     )\n\u001b[1;32m   1931\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1932\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/langchain_core/runnables/config.py:396\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[39mif\u001b[39;00m run_manager \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    395\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m run_manager\n\u001b[0;32m--> 396\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/langchain_core/runnables/passthrough.py:481\u001b[0m, in \u001b[0;36mRunnableAssign._invoke\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mThe input to RunnablePassthrough.assign() must be a dict.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    477\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)  \u001b[39m# noqa: TRY004\u001b[39;00m\n\u001b[1;32m    479\u001b[0m \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m    480\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m,\n\u001b[0;32m--> 481\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmapper\u001b[39m.\u001b[39;49minvoke(\n\u001b[1;32m    482\u001b[0m         \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    483\u001b[0m         patch_config(config, callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child()),\n\u001b[1;32m    484\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    485\u001b[0m     ),\n\u001b[1;32m    486\u001b[0m }\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/langchain_core/runnables/base.py:3729\u001b[0m, in \u001b[0;36mRunnableParallel.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3724\u001b[0m     \u001b[39mwith\u001b[39;00m get_executor_for_config(config) \u001b[39mas\u001b[39;00m executor:\n\u001b[1;32m   3725\u001b[0m         futures \u001b[39m=\u001b[39m [\n\u001b[1;32m   3726\u001b[0m             executor\u001b[39m.\u001b[39msubmit(_invoke_step, step, \u001b[39minput\u001b[39m, config, key)\n\u001b[1;32m   3727\u001b[0m             \u001b[39mfor\u001b[39;00m key, step \u001b[39min\u001b[39;00m steps\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   3728\u001b[0m         ]\n\u001b[0;32m-> 3729\u001b[0m         output \u001b[39m=\u001b[39m {key: future\u001b[39m.\u001b[39;49mresult() \u001b[39mfor\u001b[39;49;00m key, future \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(steps, futures)}\n\u001b[1;32m   3730\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[1;32m   3731\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/langchain_core/runnables/base.py:3729\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3724\u001b[0m     \u001b[39mwith\u001b[39;00m get_executor_for_config(config) \u001b[39mas\u001b[39;00m executor:\n\u001b[1;32m   3725\u001b[0m         futures \u001b[39m=\u001b[39m [\n\u001b[1;32m   3726\u001b[0m             executor\u001b[39m.\u001b[39msubmit(_invoke_step, step, \u001b[39minput\u001b[39m, config, key)\n\u001b[1;32m   3727\u001b[0m             \u001b[39mfor\u001b[39;00m key, step \u001b[39min\u001b[39;00m steps\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   3728\u001b[0m         ]\n\u001b[0;32m-> 3729\u001b[0m         output \u001b[39m=\u001b[39m {key: future\u001b[39m.\u001b[39;49mresult() \u001b[39mfor\u001b[39;00m key, future \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(steps, futures)}\n\u001b[1;32m   3730\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[1;32m   3731\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/concurrent/futures/_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    455\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 456\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    457\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs)\n\u001b[1;32m     59\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfuture\u001b[39m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/langchain_core/runnables/base.py:3713\u001b[0m, in \u001b[0;36mRunnableParallel.invoke.<locals>._invoke_step\u001b[0;34m(step, input, config, key)\u001b[0m\n\u001b[1;32m   3711\u001b[0m context \u001b[39m=\u001b[39m copy_context()\n\u001b[1;32m   3712\u001b[0m context\u001b[39m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[0;32m-> 3713\u001b[0m \u001b[39mreturn\u001b[39;00m context\u001b[39m.\u001b[39mrun(\n\u001b[1;32m   3714\u001b[0m     step\u001b[39m.\u001b[39minvoke,\n\u001b[1;32m   3715\u001b[0m     \u001b[39minput\u001b[39m,\n\u001b[1;32m   3716\u001b[0m     child_config,\n\u001b[1;32m   3717\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/langchain_core/runnables/base.py:5360\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5354\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39minvoke\u001b[39m(\n\u001b[1;32m   5355\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   5356\u001b[0m     \u001b[39minput\u001b[39m: Input,\n\u001b[1;32m   5357\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   5358\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   5359\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Output:\n\u001b[0;32m-> 5360\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbound\u001b[39m.\u001b[39;49minvoke(\n\u001b[1;32m   5361\u001b[0m         \u001b[39minput\u001b[39;49m,\n\u001b[1;32m   5362\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_merge_configs(config),\n\u001b[1;32m   5363\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m{\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs},\n\u001b[1;32m   5364\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/langchain_core/runnables/base.py:3024\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39mrun(step\u001b[39m.\u001b[39minvoke, \u001b[39minput\u001b[39m, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   3023\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 3024\u001b[0m             \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39mrun(step\u001b[39m.\u001b[39minvoke, \u001b[39minput\u001b[39m, config)\n\u001b[1;32m   3025\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[1;32m   3026\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/langchain_core/language_models/llms.py:387\u001b[0m, in \u001b[0;36mBaseLLM.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39minvoke\u001b[39m(\n\u001b[1;32m    378\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    379\u001b[0m     \u001b[39minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    384\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    385\u001b[0m     config \u001b[39m=\u001b[39m ensure_config(config)\n\u001b[1;32m    386\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 387\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[1;32m    388\u001b[0m             [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_input(\u001b[39minput\u001b[39;49m)],\n\u001b[1;32m    389\u001b[0m             stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    390\u001b[0m             callbacks\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcallbacks\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    391\u001b[0m             tags\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mtags\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    392\u001b[0m             metadata\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmetadata\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    393\u001b[0m             run_name\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mrun_name\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    394\u001b[0m             run_id\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mrun_id\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    395\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    396\u001b[0m         )\n\u001b[1;32m    397\u001b[0m         \u001b[39m.\u001b[39mgenerations[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[1;32m    398\u001b[0m         \u001b[39m.\u001b[39mtext\n\u001b[1;32m    399\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/langchain_core/language_models/llms.py:760\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mgenerate_prompt\u001b[39m(\n\u001b[1;32m    753\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    754\u001b[0m     prompts: \u001b[39mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    758\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    759\u001b[0m     prompt_strings \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_string() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[0;32m--> 760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_strings, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/langchain_core/language_models/llms.py:963\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m get_llm_cache() \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m     run_managers \u001b[39m=\u001b[39m [\n\u001b[1;32m    950\u001b[0m         callback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[1;32m    951\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_serialized,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    961\u001b[0m         )\n\u001b[1;32m    962\u001b[0m     ]\n\u001b[0;32m--> 963\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_helper(\n\u001b[1;32m    964\u001b[0m         prompts, stop, run_managers, \u001b[39mbool\u001b[39;49m(new_arg_supported), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    965\u001b[0m     )\n\u001b[1;32m    966\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n\u001b[1;32m    967\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(missing_prompts) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/langchain_core/language_models/llms.py:784\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m_generate_helper\u001b[39m(\n\u001b[1;32m    775\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    776\u001b[0m     prompts: \u001b[39mlist\u001b[39m[\u001b[39mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    780\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    781\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    782\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    783\u001b[0m         output \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 784\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[1;32m    785\u001b[0m                 prompts,\n\u001b[1;32m    786\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    787\u001b[0m                 \u001b[39m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    788\u001b[0m                 run_manager\u001b[39m=\u001b[39;49mrun_managers[\u001b[39m0\u001b[39;49m] \u001b[39mif\u001b[39;49;00m run_managers \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    789\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    790\u001b[0m             )\n\u001b[1;32m    791\u001b[0m             \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    792\u001b[0m             \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(prompts, stop\u001b[39m=\u001b[39mstop)\n\u001b[1;32m    793\u001b[0m         )\n\u001b[1;32m    794\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    795\u001b[0m         \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/langchain_openai/llms/base.py:343\u001b[0m, in \u001b[0;36mBaseOpenAI._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m     choices\u001b[39m.\u001b[39mappend(\n\u001b[1;32m    328\u001b[0m         {\n\u001b[1;32m    329\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m: generation\u001b[39m.\u001b[39mtext,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    340\u001b[0m         }\n\u001b[1;32m    341\u001b[0m     )\n\u001b[1;32m    342\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 343\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(prompt\u001b[39m=\u001b[39;49m_prompts, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    344\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, \u001b[39mdict\u001b[39m):\n\u001b[1;32m    345\u001b[0m         \u001b[39m# V1 client returns the response in an PyDantic object instead of\u001b[39;00m\n\u001b[1;32m    346\u001b[0m         \u001b[39m# dict. For the transition period, we deep convert it to dict.\u001b[39;00m\n\u001b[1;32m    347\u001b[0m         response \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mmodel_dump()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/openai/_utils/_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m             msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing required argument: \u001b[39m\u001b[39m{\u001b[39;00mquote(missing[\u001b[39m0\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 279\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/openai/resources/completions.py:539\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, model, prompt, best_of, echo, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, seed, stop, stream, stream_options, suffix, temperature, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[39m@required_args\u001b[39m([\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m\"\u001b[39m], [\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    511\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcreate\u001b[39m(\n\u001b[1;32m    512\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    537\u001b[0m     timeout: \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m httpx\u001b[39m.\u001b[39mTimeout \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m|\u001b[39m NotGiven \u001b[39m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    538\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Completion \u001b[39m|\u001b[39m Stream[Completion]:\n\u001b[0;32m--> 539\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[1;32m    540\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m/completions\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    541\u001b[0m         body\u001b[39m=\u001b[39;49mmaybe_transform(\n\u001b[1;32m    542\u001b[0m             {\n\u001b[1;32m    543\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m: model,\n\u001b[1;32m    544\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mprompt\u001b[39;49m\u001b[39m\"\u001b[39;49m: prompt,\n\u001b[1;32m    545\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mbest_of\u001b[39;49m\u001b[39m\"\u001b[39;49m: best_of,\n\u001b[1;32m    546\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mecho\u001b[39;49m\u001b[39m\"\u001b[39;49m: echo,\n\u001b[1;32m    547\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfrequency_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: frequency_penalty,\n\u001b[1;32m    548\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogit_bias\u001b[39;49m\u001b[39m\"\u001b[39;49m: logit_bias,\n\u001b[1;32m    549\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogprobs\u001b[39;49m\u001b[39m\"\u001b[39;49m: logprobs,\n\u001b[1;32m    550\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmax_tokens\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_tokens,\n\u001b[1;32m    551\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mn\u001b[39;49m\u001b[39m\"\u001b[39;49m: n,\n\u001b[1;32m    552\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mpresence_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: presence_penalty,\n\u001b[1;32m    553\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mseed\u001b[39;49m\u001b[39m\"\u001b[39;49m: seed,\n\u001b[1;32m    554\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstop\u001b[39;49m\u001b[39m\"\u001b[39;49m: stop,\n\u001b[1;32m    555\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstream\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream,\n\u001b[1;32m    556\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstream_options\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream_options,\n\u001b[1;32m    557\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39msuffix\u001b[39;49m\u001b[39m\"\u001b[39;49m: suffix,\n\u001b[1;32m    558\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtemperature\u001b[39;49m\u001b[39m\"\u001b[39;49m: temperature,\n\u001b[1;32m    559\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_p\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_p,\n\u001b[1;32m    560\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m: user,\n\u001b[1;32m    561\u001b[0m             },\n\u001b[1;32m    562\u001b[0m             completion_create_params\u001b[39m.\u001b[39;49mCompletionCreateParams,\n\u001b[1;32m    563\u001b[0m         ),\n\u001b[1;32m    564\u001b[0m         options\u001b[39m=\u001b[39;49mmake_request_options(\n\u001b[1;32m    565\u001b[0m             extra_headers\u001b[39m=\u001b[39;49mextra_headers, extra_query\u001b[39m=\u001b[39;49mextra_query, extra_body\u001b[39m=\u001b[39;49mextra_body, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    566\u001b[0m         ),\n\u001b[1;32m    567\u001b[0m         cast_to\u001b[39m=\u001b[39;49mCompletion,\n\u001b[1;32m    568\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    569\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mStream[Completion],\n\u001b[1;32m    570\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/openai/_base_client.py:1290\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1276\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mpost\u001b[39m(\n\u001b[1;32m   1277\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1278\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1285\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1286\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m   1287\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(\n\u001b[1;32m   1288\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mto_httpx_files(files), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[1;32m   1289\u001b[0m     )\n\u001b[0;32m-> 1290\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(cast_to, opts, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/openai/_base_client.py:967\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m     retries_taken \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 967\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[1;32m    968\u001b[0m     cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[1;32m    969\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m    970\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    971\u001b[0m     stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m    972\u001b[0m     retries_taken\u001b[39m=\u001b[39;49mretries_taken,\n\u001b[1;32m    973\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/openai/_base_client.py:1056\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[39mif\u001b[39;00m remaining_retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_retry(err\u001b[39m.\u001b[39mresponse):\n\u001b[1;32m   1055\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mclose()\n\u001b[0;32m-> 1056\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retry_request(\n\u001b[1;32m   1057\u001b[0m         input_options,\n\u001b[1;32m   1058\u001b[0m         cast_to,\n\u001b[1;32m   1059\u001b[0m         retries_taken\u001b[39m=\u001b[39;49mretries_taken,\n\u001b[1;32m   1060\u001b[0m         response_headers\u001b[39m=\u001b[39;49merr\u001b[39m.\u001b[39;49mresponse\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m   1061\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m   1062\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m   1063\u001b[0m     )\n\u001b[1;32m   1065\u001b[0m \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1067\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/openai/_base_client.py:1105\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[39m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1102\u001b[0m \u001b[39m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1103\u001b[0m time\u001b[39m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1105\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[1;32m   1106\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m   1107\u001b[0m     cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[1;32m   1108\u001b[0m     retries_taken\u001b[39m=\u001b[39;49mretries_taken \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[1;32m   1109\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m   1110\u001b[0m     stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m   1111\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/openai/_base_client.py:1056\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[39mif\u001b[39;00m remaining_retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_retry(err\u001b[39m.\u001b[39mresponse):\n\u001b[1;32m   1055\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mclose()\n\u001b[0;32m-> 1056\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retry_request(\n\u001b[1;32m   1057\u001b[0m         input_options,\n\u001b[1;32m   1058\u001b[0m         cast_to,\n\u001b[1;32m   1059\u001b[0m         retries_taken\u001b[39m=\u001b[39;49mretries_taken,\n\u001b[1;32m   1060\u001b[0m         response_headers\u001b[39m=\u001b[39;49merr\u001b[39m.\u001b[39;49mresponse\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m   1061\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m   1062\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m   1063\u001b[0m     )\n\u001b[1;32m   1065\u001b[0m \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1067\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/openai/_base_client.py:1105\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[39m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1102\u001b[0m \u001b[39m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1103\u001b[0m time\u001b[39m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1105\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[1;32m   1106\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m   1107\u001b[0m     cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[1;32m   1108\u001b[0m     retries_taken\u001b[39m=\u001b[39;49mretries_taken \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[1;32m   1109\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m   1110\u001b[0m     stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m   1111\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/llmapp/lib/python3.11/site-packages/openai/_base_client.py:1071\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1068\u001b[0m         err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mread()\n\u001b[1;32m   1070\u001b[0m     log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mRe-raising status error\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1071\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_status_error_from_response(err\u001b[39m.\u001b[39mresponse) \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_response(\n\u001b[1;32m   1074\u001b[0m     cast_to\u001b[39m=\u001b[39mcast_to,\n\u001b[1;32m   1075\u001b[0m     options\u001b[39m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1079\u001b[0m     retries_taken\u001b[39m=\u001b[39mretries_taken,\n\u001b[1;32m   1080\u001b[0m )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What is stats?\"})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
